% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/csv_to_binary.R
\name{csv_to_binary}
\alias{csv_to_binary}
\title{Convert CSV data into binary format}
\usage{
csv_to_binary(input_dir, output_dir, metadata, data_set_id)
}
\arguments{
\item{input_dir}{character. Path. The directory that contains the raw data files.}

\item{output_dir}{Character. Path of the directory in which to write the output binary data files.}

\item{metadata}{List. Dictionary containing the column definitions.}

\item{data_set_id}{character. Data set identifier e.g. "apc", "op"}
}
\value{
List of paths of the new output files.
}
\description{
The code uses DuckDB to perform file format conversion.

By default, this function will read all the CSV files in the \code{input_dir} and convert them to
\href{https://parquet.apache.org/}{Apache Parquet} format.

The resultant binary data files will be written to \code{output_dir}.

A \href{https://www.json.org/json-en.html}{JSON} file must be specified that contains an object where the keys are the
headers of the input CSV files in order and the values are the SQL data types (default to \code{"VARCHAR"}). The location
of this file is stored in the \code{data_types_path} variable and defaults to
\verb{inst/extdata/sql_data_types/\{data_set_id\}.json}.

See:
\itemize{
\item \href{https://duckdb.org/docs/api/r}{DuckDB R API}
\item \href{https://dbi.r-dbi.org/}{DBI documentation}
\item DuckDB \href{https://duckdb.org/docs/data/csv/overview.html}{CSV Import}
}
}
